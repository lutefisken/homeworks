{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашка 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gensim\n",
    "import csv\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                      предложение 1  \\\n",
      "0           0  Полицейским разрешат стрелять на поражение по ...   \n",
      "1           1  Право полицейских на проникновение в жилище ре...   \n",
      "2           2  Президент Египта ввел чрезвычайное положение в...   \n",
      "3           3  Вернувшихся из Сирии россиян волнует вопрос тр...   \n",
      "4           4  В Москву из Сирии вернулись 2 самолета МЧС с р...   \n",
      "\n",
      "                                       предложение 2  класс  \\\n",
      "0  Полиции могут разрешить стрелять по хулиганам ...      0   \n",
      "1  Правила внесудебного проникновения полицейских...      0   \n",
      "2  Власти Египта угрожают ввести в стране чрезвыч...      0   \n",
      "3  Самолеты МЧС вывезут россиян из разрушенной Си...     -1   \n",
      "4  Самолеты МЧС вывезут россиян из разрушенной Си...      0   \n",
      "\n",
      "                                             леммы 1  \\\n",
      "0  полицейский разрешать стрелять поражение гражд...   \n",
      "1  право полицейский проникновение жилище решать ...   \n",
      "2  президент египет вводить чрезвычайный положени...   \n",
      "3  вернуться сирия россиянин волновать вопрос тру...   \n",
      "4  москва сирия вернуться два самолет мчс россиян...   \n",
      "\n",
      "                                             леммы 2  \\\n",
      "0  полиция мочь разрешать стрелять хулиган травма...   \n",
      "1  правило внесудебный проникновение полицейский ...   \n",
      "2  власть египет угрожать вводить страна чрезвыча...   \n",
      "3     самолет мчс вывозить россиянин разрушать сирия   \n",
      "4     самолет мчс вывозить россиянин разрушать сирия   \n",
      "\n",
      "                                              грамм1  \\\n",
      "0  S,муж,од=(дат,мн|твор,ед) V,пе=непрош,мн,изъяв...   \n",
      "1  ADV,вводн= S,муж,од=(пр,мн|вин,мн|род,мн) S,ср...   \n",
      "2  S,муж,од=им,ед S,гео,муж,неод=род,ед V=прош,ед...   \n",
      "3  V,сов,нп=(прош,пр,мн,прич,полн,действ|прош,род...   \n",
      "4  S,гео,жен,неод=вин,ед S,гео,жен,неод=(пр,ед|ви...   \n",
      "\n",
      "                                              грамм2  \\\n",
      "0  S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн) ...   \n",
      "1  S,сред,неод=(вин,мн|род,ед|им,мн) A,полн=(вин,...   \n",
      "2  S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн) ...   \n",
      "3  S,муж,неод=(вин,мн|им,мн) S,сред,неод=(пр,мн|п...   \n",
      "4  S,муж,неод=(вин,мн|им,мн) S,сред,неод=(пр,мн|п...   \n",
      "\n",
      "                                                  г1  \\\n",
      "0  S,муж,од=(дат,мн|твор,ед) V,пе=непрош,мн,изъяв...   \n",
      "1  ADV,вводн= S,муж,од=(пр,мн|вин,мн|род,мн) PR= ...   \n",
      "2  S,муж,од=им,ед S,гео,муж,неод=род,ед V=прош,ед...   \n",
      "3  V,сов,нп=(прош,пр,мн,прич,полн,действ|прош,род...   \n",
      "4  PR= S,гео,жен,неод=вин,ед PR= S,гео,жен,неод=(...   \n",
      "\n",
      "                                                  г2   ...     сказ_1  \\\n",
      "0  S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн) ...   ...     [1, 2]   \n",
      "1  S,сред,неод=(вин,мн|род,ед|им,мн) A,полн=(вин,...   ...     [6, 7]   \n",
      "2  S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн) ...   ...        [2]   \n",
      "3  S,муж,неод=(вин,мн|им,мн) S,сред,неод=(пр,мн|п...   ...        [4]   \n",
      "4  S,муж,неод=(вин,мн|им,мн) S,сред,неод=(пр,мн|п...   ...        [4]   \n",
      "\n",
      "      подл_1 гр_подл_1   доп_1   гр_доп_1     сказ_2  подл_2 гр_подл_2  \\\n",
      "0         []        []      []  [4, 6, 8]  [1, 2, 3]      []        []   \n",
      "1         []        []     [1]     [5, 3]        [6]      []        []   \n",
      "2     [0, 1]        []  [4, 3]     [7, 6]     [2, 3]  [0, 1]        []   \n",
      "3     [5, 6]       [8]      []     [3, 2]        [2]  [0, 1]        []   \n",
      "4  [5, 6, 7]   [9, 11]      []     [3, 1]        [2]  [0, 1]        []   \n",
      "\n",
      "          доп_2 гр_доп_2  \n",
      "0           [0]       []  \n",
      "1  [0, 3, 2, 1]      [5]  \n",
      "2        [7, 6]      [5]  \n",
      "3           [3]   [6, 5]  \n",
      "4           [3]   [6, 5]  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "(7227, 22)\n",
      "   Unnamed: 0                                      предложение 1  \\\n",
      "0           0                    Цены на нефть восстанавливаются   \n",
      "1           1  \"Гоголь-центр\" покажет видеозапись скандальног...   \n",
      "2           2  Агент: РФС вновь задерживает зарплату Фабио Ка...   \n",
      "3           3     День Победы в Москве обещает выдаться облачным   \n",
      "4           4  Посол РФ в США: Россия будет бороться с попытк...   \n",
      "\n",
      "                                       предложение 2  класс  \\\n",
      "0  Парламент Словакии поблагодарил народы бывшего...     -1   \n",
      "1  Кехман запретил «Гоголь-центру» показывать вид...     -1   \n",
      "2  СМИ: Агент Фабио Капелло грозится подать в суд...     -1   \n",
      "3   Любляна отпразднует День Победы вместе с Москвой     -1   \n",
      "4  Правительство запланировало заработать на лоте...     -1   \n",
      "\n",
      "                                             леммы 1  \\\n",
      "0                       цена нефть восстанавливаться   \n",
      "1  гоголь центр показывать видеозапись скандальны...   \n",
      "2  агент РФС вновь задерживать зарплата фабио кап...   \n",
      "3     день победа москва обещать выдаваться облачный   \n",
      "4  посол рф сша россия быть бороться попытка пере...   \n",
      "\n",
      "                                             леммы 2  \\\n",
      "0  парламент словакия поблагодарить народ бывший ...   \n",
      "1  кехман запрещать гоголь центр показывать видео...   \n",
      "2  сми агент фабио капелло грозиться подавать суд...   \n",
      "3    любляна отпраздновать день победа вместе москва   \n",
      "4  правительство запланировать зарабатывать лотер...   \n",
      "\n",
      "                                              грамм1  \\\n",
      "0  S,жен,неод=(вин,мн|род,ед|им,мн) S,жен,неод=(в...   \n",
      "1  S,муж,од=им,ед S,муж,неод=(вин,ед|им,ед) V=неп...   \n",
      "2  S,муж,од=им,ед X= ADV= V,пе=непрош,ед,изъяв,3-...   \n",
      "3  S,муж,неод=(вин,ед|им,ед) S,жен,неод=(вин,мн|р...   \n",
      "4  S,муж,од=им,ед S,сокр,гео,ед,жен,неод=(пр|вин|...   \n",
      "\n",
      "                                              грамм2  \\\n",
      "0  S,муж,неод=(вин,ед|им,ед) S,гео,жен,неод=(пр,е...   \n",
      "1  S,фам,муж,од=им,ед V,пе=прош,ед,изъяв,муж,сов ...   \n",
      "2  S,сокр,мн,неод=(пр|вин|дат|род|твор|им) S,муж,...   \n",
      "3  S,жен,неод=им,ед V,сов,пе=непрош,ед,изъяв,3-л ...   \n",
      "4  S,сред,неод=(вин,ед|им,ед) V,сов,пе=прош,ед,из...   \n",
      "\n",
      "                                                  г1  \\\n",
      "0  S,жен,неод=(вин,мн|род,ед|им,мн) PR= S,жен,нео...   \n",
      "1  S,муж,од=им,ед S,муж,неод=(вин,ед|им,ед) V=неп...   \n",
      "2  S,муж,од=им,ед X= ADV= V,пе=непрош,ед,изъяв,3-...   \n",
      "3  S,муж,неод=(вин,ед|им,ед) S,жен,неод=(вин,мн|р...   \n",
      "4  S,муж,од=им,ед S,сокр,гео,ед,жен,неод=(пр|вин|...   \n",
      "\n",
      "                                                  г2   ...     сказ_1  подл_1  \\\n",
      "0  S,муж,неод=(вин,ед|им,ед) S,гео,жен,неод=(пр,е...   ...        [3]     [0]   \n",
      "1  S,фам,муж,од=им,ед V,пе=прош,ед,изъяв,муж,сов ...   ...        [2]     [1]   \n",
      "2  S,сокр,мн,неод=(пр|вин|дат|род|твор|им) S,муж,...   ...        [3]     [0]   \n",
      "3  S,жен,неод=им,ед V,сов,пе=непрош,ед,изъяв,3-л ...   ...     [4, 5]  [0, 1]   \n",
      "4  S,сред,неод=(вин,ед|им,ед) V,сов,пе=прош,ед,из...   ...     [5, 6]  [4, 3]   \n",
      "\n",
      "  гр_подл_1      доп_1 гр_доп_1  сказ_2     подл_2 гр_подл_2      доп_2  \\\n",
      "0       [2]         []       []     [2]     [0, 1]        []  [3, 5, 4]   \n",
      "1        []  [3, 4, 5]      [6]     [1]        [0]        []         []   \n",
      "2       [1]  [4, 5, 6]       []  [4, 5]  [1, 3, 2]        []         []   \n",
      "3       [3]         []       []     [1]        [0]        []     [2, 3]   \n",
      "4        []         []      [8]  [1, 2]        [0]        []     [5, 6]   \n",
      "\n",
      "  гр_доп_2  \n",
      "0      [7]  \n",
      "1       []  \n",
      "2      [7]  \n",
      "3       []  \n",
      "4   [4, 7]  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "(1924, 22)\n"
     ]
    }
   ],
   "source": [
    "train, test = pd.read_csv('train_6b.csv'), pd.read_csv('test_6b.csv')\n",
    "# с диплома остался парафразер с очень тщательной нормализацией\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "print(test.head())\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение одного мистического корпуса\n",
    "sentences = []\n",
    "sentences_raw = []\n",
    "for file in os.listdir(os.path.join(os.getcwd(),'corpus')):\n",
    "    with open('corpus/' + file, 'r', encoding='utf-8') as  f:\n",
    "        sentence = []\n",
    "        reader = csv.reader(f, delimiter=';')\n",
    "        for line in reader:\n",
    "            word = line[2]\n",
    "            if word.isalpha():\n",
    "                sentence.append(word.lower())\n",
    "        sentences.append(sentence)\n",
    "        sentences_raw.append(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['год', 'на', 'ямал', 'более', 'или', 'менее', 'нормальный', 'погода', 'держаться', 'в', 'сочи', 'несколько', 'день', 'начинать', 'портиться', 'связанный', 'это', 'с', 'прохождение', 'атмосферный']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer( max_features=1000)\n",
    "X = cv.fit_transform(sentences_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['погода', 'мчс', 'снежный', 'пожарный', 'столица', 'госпитализировать', 'температура', 'чп', 'сообщение', 'встречный']\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(50)\n",
    "svd.fit(X)\n",
    "pickle.dump(svd, open('svd', 'wb'))\n",
    "id2word = {i:w for i,w in enumerate(cv.get_feature_names())}\n",
    "word2id = {w:i for i,w in id2word.items()}\n",
    "id2vec_svd = svd.components_.T\n",
    "def most_similar(word, id2vec):\n",
    "    similar = [id2word[i] for i in cosine_distances(id2vec[word2id[word]].reshape(1, -1), id2vec).argsort()[0][:10]]\n",
    "    return similar\n",
    "print(most_similar('погода', id2vec_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['погода', 'мчс', 'снежный', 'ожидаться', 'полоса', 'ночь', 'пожарный', 'секунда', 'трасса', 'аэропорт']\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(6)\n",
    "nmf.fit(X)\n",
    "pickle.dump(nmf, open('nmf', 'wb'))\n",
    "id2vec_nmf = nmf.components_.T\n",
    "print(most_similar('погода', id2vec_nmf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text = gensim.models.FastText(sentences, min_n=1)\n",
    "fast_text.save('fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('подмога', 0.9999983310699463),\n",
       " ('пахомов', 0.9999969005584717),\n",
       " ('пожаро', 0.9999966621398926),\n",
       " ('выгода', 0.9999966025352478),\n",
       " ('автодром', 0.999996542930603),\n",
       " ('автодорога', 0.9999964237213135),\n",
       " ('автопром', 0.9999961853027344),\n",
       " ('вода', 0.9999960064888),\n",
       " ('автодор', 0.9999960064888),\n",
       " ('ягода', 0.9999960064888)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text.wv.most_similar('погода')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec(sentences, size=50, sg=1)\n",
    "w2v.save('w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('областной', 0.9963815212249756),\n",
       " ('региональный', 0.9956607818603516),\n",
       " ('прокуратура', 0.9955354332923889),\n",
       " ('администрация', 0.9954781532287598),\n",
       " ('брянский', 0.9953436851501465),\n",
       " ('псковский', 0.9945963025093079),\n",
       " ('су', 0.993961751461029),\n",
       " ('правительство', 0.9921631813049316),\n",
       " ('край', 0.9914276003837585),\n",
       " ('информация', 0.991313636302948)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('мчс')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,test]) # возьмем все, а потом сделаем к фолд\n",
    "cv_train1 = cv.transform(train['леммы 1']\n",
    "cv_train2 = cv.transform(train['леммы 2']                    \n",
    "svd_feature = cosine_distances(svd.transform(cv_train1), svd.transform(cv_train2))\n",
    "nmf_feature = cosine_distances(nmf.transform(cv_train1),nmf.transform(cv_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model, dim):\n",
    "    text = text.split()\n",
    "    \n",
    "    # чтобы не доставать одно слово несколько раз\n",
    "    # сделаем счетчик, а потом векторы домножим на частоту\n",
    "    words = Counter(text)\n",
    "    total = len(text)\n",
    "    vectors = np.zeros((len(words), dim))\n",
    "    \n",
    "    for i,word in enumerate(words):\n",
    "        try:\n",
    "            v = model[word]\n",
    "            vectors[i] = v*(words[word]/total) # просто умножаем вектор на частоту\n",
    "        except (KeyError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    if vectors.any():\n",
    "        vector = np.average(vectors, axis=0)\n",
    "    else:\n",
    "        vector = np.zeros((dim))\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50\n",
    "X_text_1_w2v = np.zeros((len(train['леммы 1']), dim))\n",
    "X_text_2_w2v = np.zeros((len(train['леммы 2']), dim))\n",
    "\n",
    "for i, text in enumerate(train['леммы 1'].apply(split()).values):\n",
    "    X_text_1_w2v[i] = get_embedding(text, w2v, dim)\n",
    "    \n",
    "for i, text in enumerate(len(train['леммы 2'].apply(split()).values):\n",
    "    X_text_2_w2v[i] = get_embedding(text, w2v, dim)\n",
    "                         \n",
    "w2v_feature = cosine_distances(X_text_1_w2v,X_text_2_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50\n",
    "X_text_1_fast_text = np.zeros((len(train['леммы 1']), dim))\n",
    "X_text_2_fast_text = np.zeros((len(train['леммы 2']), dim))\n",
    "\n",
    "for i, text in enumerate(train['леммы 1'].values):\n",
    "    X_text_1_fast_text[i] = get_embedding(text, fast_text, dim)\n",
    "    \n",
    "for i, text in enumerate(len(train['леммы 2'].values):\n",
    "    X_text_2_fast_text[i] = get_embedding(text, fast_text, dim)\n",
    "                         \n",
    "fast_text_feature = cosine_distances(X_text_1_fast_text,X_text_2_fast_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm = adagram.VectorModel.load('all.a010.p10.d300.w5.m100.nonorm.slim.joblib')\n",
    "def get_embedding_adagram(text, model, window, dim):\n",
    "    text = text.split()\n",
    "    \n",
    "    \n",
    "    word2context = []\n",
    "    for i in range(len(text)-1):\n",
    "        left = max(0, i-window)\n",
    "        word = text[i]\n",
    "        left_context = text[left:i]\n",
    "        right_context = text[i+1:i+window]\n",
    "        context = left_context + right_context\n",
    "        word2context.append((word, context))\n",
    "    \n",
    "    \n",
    "    \n",
    "    vectors = np.zeros((len(word2context), dim))\n",
    "    \n",
    "    for i,word in enumerate(word2context):\n",
    "        word, context = word\n",
    "        try:\n",
    "            sense = model.disambiguate(word, context).argmax()\n",
    "            v = model.sense_vector(word, sense)\n",
    "            vectors[i] = v # просто умножаем вектор на частоту\n",
    "        \n",
    "        except (KeyError, ValueError):\n",
    "            continue\n",
    "    \n",
    "    if vectors.any():\n",
    "        vector = np.average(vectors, axis=0)\n",
    "    else:\n",
    "        vector = np.zeros((dim))\n",
    "    \n",
    "    return vector\n",
    "dim = 100\n",
    "X_text_1_adagram = np.zeros((len(train['леммы 1']), dim))\n",
    "X_text_2_adagram = np.zeros((len(train['леммы 1']), dim))\n",
    "\n",
    "for i, text in enumerate(train['леммы 1'].values):\n",
    "    X_text_1[i] = get_embedding_adagram(text, vm, 5, dim)\n",
    "    \n",
    "for i, text in enumerate(train['леммы 1'].values):\n",
    "    X_text_2[i] = get_embedding_adagram(text, vm, 5, dim)\n",
    "adagram_feature = cosine_distances(X_text_1_adagram,X_text_2_adagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([adagram_feature,fast_text_feature,w2v_feature,svd_feature,nmf_feature])\n",
    "y= train['класс']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "f1_scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=200,\n",
    "                             class_weight='balanced')\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    f1_scores.append(f1_score(y_test, preds, average='micro'))\n",
    "    \n",
    "print(np.mean(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как улучшить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* вместо эмбеддингов брать метрики по RuWordNet (улучшится ненамного, и не хочется повторять диплом)\n",
    "* разметить например UDPipe и считать схожесть между словами с одинаковыми синтаксическими тегами\n",
    "\n",
    "нет ничего стремнее, чем использовать чужие норм идеи, когда нет своих"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вот отсюда https://github.com/ufal/udpipe/blob/master/bindings/python/examples/udpipe_model.py\n",
    "import ufal.udpipe \n",
    "\n",
    "class Model:\n",
    "    def __init__(self, path):\n",
    "        \"\"\"Load given model.\"\"\"\n",
    "        self.model = ufal.udpipe.Model.load(path)\n",
    "        if not self.model:\n",
    "            raise Exception(\"Cannot load UDPipe model from file '%s'\" % path)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenize the text and return list of ufal.udpipe.Sentence-s.\"\"\"\n",
    "        tokenizer = self.model.newTokenizer(self.model.DEFAULT)\n",
    "        if not tokenizer:\n",
    "            raise Exception(\"The model does not have a tokenizer\")\n",
    "        return self._read(text, tokenizer)\n",
    "\n",
    "    def read(self, text, in_format):\n",
    "        \"\"\"Load text in the given format (conllu|horizontal|vertical) and return list of ufal.udpipe.Sentence-s.\"\"\"\n",
    "        input_format = ufal.udpipe.InputFormat.newInputFormat(in_format)\n",
    "        if not input_format:\n",
    "            raise Exception(\"Cannot create input format '%s'\" % in_format)\n",
    "        return self._read(text, input_format)\n",
    "\n",
    "    def _read(self, text, input_format):\n",
    "        input_format.setText(text)\n",
    "        error = ufal.udpipe.ProcessingError()\n",
    "        sentences = []\n",
    "\n",
    "        sentence = ufal.udpipe.Sentence()\n",
    "        while input_format.nextSentence(sentence, error):\n",
    "            sentences.append(sentence)\n",
    "            sentence = ufal.udpipe.Sentence()\n",
    "        if error.occurred():\n",
    "            raise Exception(error.message)\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    def tag(self, sentence):\n",
    "        \"\"\"Tag the given ufal.udpipe.Sentence (inplace).\"\"\"\n",
    "        self.model.tag(sentence, self.model.DEFAULT)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        \"\"\"Parse the given ufal.udpipe.Sentence (inplace).\"\"\"\n",
    "        self.model.parse(sentence, self.model.DEFAULT)\n",
    "\n",
    "    def write(self, sentences, out_format):\n",
    "        \"\"\"Write given ufal.udpipe.Sentence-s in the required format (conllu|horizontal|vertical).\"\"\"\n",
    "\n",
    "        output_format = ufal.udpipe.OutputFormat.newOutputFormat(out_format)\n",
    "        output = ''\n",
    "        for sentence in sentences:\n",
    "            output += output_format.writeSentence(sentence)\n",
    "        output += output_format.finishDocument()\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                      предложение 1  \\\n",
      "0           0  Полицейским разрешат стрелять на поражение по ...   \n",
      "1           1  Право полицейских на проникновение в жилище ре...   \n",
      "2           2  Президент Египта ввел чрезвычайное положение в...   \n",
      "3           3  Вернувшихся из Сирии россиян волнует вопрос тр...   \n",
      "4           4  В Москву из Сирии вернулись 2 самолета МЧС с р...   \n",
      "\n",
      "                                       предложение 2  класс  \\\n",
      "0  Полиции могут разрешить стрелять по хулиганам ...      0   \n",
      "1  Правила внесудебного проникновения полицейских...      0   \n",
      "2  Власти Египта угрожают ввести в стране чрезвыч...      0   \n",
      "3  Самолеты МЧС вывезут россиян из разрушенной Си...     -1   \n",
      "4  Самолеты МЧС вывезут россиян из разрушенной Си...      0   \n",
      "\n",
      "                                             леммы 1  \\\n",
      "0  полицейский разрешать стрелять поражение гражд...   \n",
      "1  право полицейский проникновение жилище решать ...   \n",
      "2  президент египет вводить чрезвычайный положени...   \n",
      "3  вернуться сирия россиянин волновать вопрос тру...   \n",
      "4  москва сирия вернуться два самолет мчс россиян...   \n",
      "\n",
      "                                             леммы 2  \\\n",
      "0  полиция мочь разрешать стрелять хулиган травма...   \n",
      "1  правило внесудебный проникновение полицейский ...   \n",
      "2  власть египет угрожать вводить страна чрезвыча...   \n",
      "3     самолет мчс вывозить россиянин разрушать сирия   \n",
      "4     самолет мчс вывозить россиянин разрушать сирия   \n",
      "\n",
      "                                              грамм1  \\\n",
      "0  S,муж,од=(дат,мн|твор,ед) V,пе=непрош,мн,изъяв...   \n",
      "1  ADV,вводн= S,муж,од=(пр,мн|вин,мн|род,мн) S,ср...   \n",
      "2  S,муж,од=им,ед S,гео,муж,неод=род,ед V=прош,ед...   \n",
      "3  V,сов,нп=(прош,пр,мн,прич,полн,действ|прош,род...   \n",
      "4  S,гео,жен,неод=вин,ед S,гео,жен,неод=(пр,ед|ви...   \n",
      "\n",
      "                                              грамм2  \\\n",
      "0  S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн) ...   \n",
      "1  S,сред,неод=(вин,мн|род,ед|им,мн) A,полн=(вин,...   \n",
      "2  S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн) ...   \n",
      "3  S,муж,неод=(вин,мн|им,мн) S,сред,неод=(пр,мн|п...   \n",
      "4  S,муж,неод=(вин,мн|им,мн) S,сред,неод=(пр,мн|п...   \n",
      "\n",
      "                                                  г1  \\\n",
      "0  S,муж,од=(дат,мн|твор,ед) V,пе=непрош,мн,изъяв...   \n",
      "1  ADV,вводн= S,муж,од=(пр,мн|вин,мн|род,мн) PR= ...   \n",
      "2  S,муж,од=им,ед S,гео,муж,неод=род,ед V=прош,ед...   \n",
      "3  V,сов,нп=(прош,пр,мн,прич,полн,действ|прош,род...   \n",
      "4  PR= S,гео,жен,неод=вин,ед PR= S,гео,жен,неод=(...   \n",
      "\n",
      "                                                  г2  \\\n",
      "0  S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн) ...   \n",
      "1  S,сред,неод=(вин,мн|род,ед|им,мн) A,полн=(вин,...   \n",
      "2  S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн) ...   \n",
      "3  S,муж,неод=(вин,мн|им,мн) S,сред,неод=(пр,мн|п...   \n",
      "4  S,муж,неод=(вин,мн|им,мн) S,сред,неод=(пр,мн|п...   \n",
      "\n",
      "                         ...                         гр_подл_1   доп_1  \\\n",
      "0                        ...                                []      []   \n",
      "1                        ...                                []     [1]   \n",
      "2                        ...                                []  [4, 3]   \n",
      "3                        ...                               [8]      []   \n",
      "4                        ...                           [9, 11]      []   \n",
      "\n",
      "    гр_доп_1     сказ_2  подл_2 гр_подл_2         доп_2 гр_доп_2  \\\n",
      "0  [4, 6, 8]  [1, 2, 3]      []        []           [0]       []   \n",
      "1     [5, 3]        [6]      []        []  [0, 3, 2, 1]      [5]   \n",
      "2     [7, 6]     [2, 3]  [0, 1]        []        [7, 6]      [5]   \n",
      "3     [3, 2]        [2]  [0, 1]        []           [3]   [6, 5]   \n",
      "4     [3, 1]        [2]  [0, 1]        []           [3]   [6, 5]   \n",
      "\n",
      "                                             syntax1  \\\n",
      "0  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = По...   \n",
      "1  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = Пр...   \n",
      "2  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = Пр...   \n",
      "3  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = Ве...   \n",
      "4  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = В ...   \n",
      "\n",
      "                                             syntax2  \n",
      "0  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = По...  \n",
      "1  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = Пр...  \n",
      "2  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = Вл...  \n",
      "3  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = Са...  \n",
      "4  # newdoc\\n# newpar\\n# sent_id = 1\\n# text = Са...  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "model = Model('russian-syntagrus-ud-2.0-170801.udpipe')\n",
    "sent1, sent2 = [], []\n",
    "\n",
    "def to_conllu(sent, out):\n",
    "    for tr in sent:\n",
    "        sentences = model.tokenize(tr)\n",
    "        for s in sentences:\n",
    "            model.tag(s)\n",
    "            model.parse(s)\n",
    "        conllu = model.write(sentences, \"conllu\")\n",
    "        out.append(conllu)\n",
    "\n",
    "to_conllu(train['предложение 1'], sent1)\n",
    "to_conllu(train['предложение 2'], sent2)\n",
    "train.loc[:,'syntax1']=pd.Series(sent1)\n",
    "train.loc[:,'syntax2']=pd.Series(sent2)\n",
    "train.to_csv('paraphraser_train.csv') # парсинг работает быстро, но не совсем, поэтому сохраним\n",
    "sent1, sent2 = [], []\n",
    "to_conllu(test['предложение 1'], sent1)\n",
    "to_conllu(test['предложение 2'], sent2)\n",
    "test.loc[:,'syntax1']=pd.Series(sent1)\n",
    "test.loc[:,'syntax2']=pd.Series(sent2)\n",
    "test.to_csv('paraphraser_test.csv')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compling",
   "language": "python",
   "name": "compling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
